{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.992\n",
      "1    0.843\n",
      "2    0.860\n",
      "3    1.073\n",
      "4    1.038\n",
      "Name: B1THD, dtype: float64\n",
      "Empty DataFrame\n",
      "Columns: [GIAGE1, HA_HEIGHT, HA_WEIGHT, TUDRPRWK, QLFXST51, rs13303327, rs36066545, rs139603701, rs10779795, rs3765971, rs4908776, rs10746495, rs2791655, rs938295, rs698891, rs4912085, rs10917477, rs1767447, rs1318236, rs12756110, rs3971300, rs142072330, rs79364962, rs34553872, rs6680369, rs680386, rs12135380, rs760938, rs7546500, rs4589135, rs79598313, rs4360494, rs67758468, rs61780429, rs35329209, rs10493130, rs1777277, rs75660521, rs12034786, rs12031054, rs983034, rs2566752, rs2820501, rs78252812, rs7554551, rs2566774, rs11587434, rs1983853, rs12756373, rs167365, rs12042197, rs284200, rs6664489, rs114621605, rs11576308, rs660240, rs547251, rs12080074, rs3790608, rs10732635, rs1779431, rs11584380, rs72692842, rs914615, rs945508, rs1123015, rs1080789, rs913257, rs10800531, rs672740, rs56682471, rs2227607, rs1609829, rs4418639, rs6701977, rs58397787, rs1022463, rs10920352, rs7516171, rs2799098, rs17514738, rs2791559, rs183522757, rs12134534, rs2647462, rs7527300, rs2609352, rs2246221, rs6672925, rs1414660, rs142343894, rs66906321, rs4669522, rs890074, rs851320, rs4666343, rs13002567, rs563406543, rs116504838, rs34780912, ...]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 1125 columns]\n",
      "(5130, 1125)\n",
      "(5130,)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Feb  2 13:04:21 2019\n",
    "\n",
    "@author:\n",
    "\"\"\"\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from matplotlib import pyplot\n",
    "import pandas\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "NUMERICALS = ['GIAGE1', 'HA_HEIGHT', 'HA_WEIGHT', 'TUDRPRWK', 'B1FND', 'GRS_FN', 'HA_SMOKE', 'GIERACE_1.0',\n",
    "              'GIERACE_2.0', 'GIERACE_3.0', 'GIERACE_4.0', 'GIERACE_5.0', 'CLINIC_1.0','CLINIC_2.0', 'CLINIC_3.0',  \n",
    "              'CLINIC_4.0', 'CLINIC_5.0', 'CLINIC_6.0','NFWLKSPD_0.0', 'NFWLKSPD_1.0', 'NFWLKSPD_2.0']\n",
    "\n",
    "\n",
    "# change allele to number\n",
    "def allele_to_number(sample, attribute, sig_dict):\n",
    "    return sample[attribute].count(sig_dict[attribute])\n",
    "\n",
    "\n",
    "# fill numerical empty cells with median of the column, race with 1 (for white) and other categorical empty cells with the 0\n",
    "def fill_empty_cell(sample, attribute, data):\n",
    "    if pandas.isnull(sample[attribute]):\n",
    "        if attribute in NUMERICALS:\n",
    "            return data[attribute].median()\n",
    "        return int(attribute == 'GIERACE' )\n",
    "    elif attribute == 'FRAC':\n",
    "        return int(sample['FAANYSLD'] or sample['FAANYWST'] or sample['FAANYHIP'])\n",
    "    return sample[attribute]\n",
    "\n",
    "\n",
    "# calculate GRS\n",
    "def load_weight(sheet):\n",
    "    weight = []\n",
    "    df = pandas.read_excel('Estrada_63.xlsx', sheet_name=sheet)\n",
    "    w = list(df)[-1]\n",
    "    for i in range(len(df)):\n",
    "        weight.append(df.iloc[i][w])\n",
    "    return weight\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = pandas.read_excel('mros_1103snps_updated.xlsx')\n",
    "    # drop HA_SLDFXFU where only 10% is filled, drop subjectid,\n",
    "    data.drop(['HA_SLDFXFU', 'TURSMOKE', 'HA_SLDFX', 'HA_WRSTFX'], axis=1, inplace=True)\n",
    "    # make the fractures into 1 variable\n",
    "    data['FRAC'] = 0\n",
    "    for attribute in data.keys():\n",
    "        data[attribute] = data.apply(lambda sample: fill_empty_cell(sample, attribute, data), axis=1)\n",
    "    # drop the other fractured values\n",
    "    data.drop(['FAANYSLD', 'FAANYWST', 'FAANYHIP'], axis=1, inplace=True)\n",
    "    # encode the categorical data\n",
    "    data = pandas.DataFrame(pandas.get_dummies(data, columns=['GIERACE', 'CLINIC', 'NFWLKSPD']))\n",
    "    features = list(data)[22:-6]\n",
    "    # setting Y and X\n",
    "    # Y_df = np.asarray(data['B1THD'], dtype=\"|S8\")\n",
    "    Y_df = data['B1THD']\n",
    "    X_df = pandas.read_excel('norma_continu_var.xlsx')\n",
    "    # weight_LS = load_weight('LS_sex-combined_beta')\n",
    "   # feature_data = data[features]\n",
    "    # weight_LS = pandas.DataFrame(pandas.Series(weight_LS, index=features, name=0))\n",
    "    #weight_FN = load_weight('FN_sex-combined_beta')\n",
    "    # X_df['GRS_LS'] = feature_data.dot(weight_LS)\n",
    "   # X_df['GRS_FN'] = feature_data.dot(weight_FN)\n",
    "   # X_df.drop(features, axis=1, inplace=True)\n",
    "    # print(Y_df.shape)\n",
    "    \n",
    "    #X_df.to_csv('X_variables.csv')\n",
    "    \n",
    "    print(Y_df.head())\n",
    "    print(X_df[1:1])\n",
    "    print(X_df.shape)\n",
    "    print(Y_df.shape)\n",
    "    # save data\n",
    "    with open('datamrosbmd1103_B1THD', 'wb') as data_file_handler:\n",
    "        import pickle\n",
    "\n",
    "        pickle.dump(\n",
    "            dict(\n",
    "                X=X_df,\n",
    "                Y=Y_df\n",
    "            ),\n",
    "            data_file_handler\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1104 10:00:32.203717 42180 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1104 10:00:32.215685 42180 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1104 10:00:32.217680 42180 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W1104 10:00:32.236629 42180 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1104 10:00:32.319409 42180 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1104 10:00:32.323399 42180 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4104, 1125)\n",
      "4104 train samples\n",
      "1026 test samples\n",
      "Train on 4104 samples, validate on 1026 samples\n",
      "Epoch 1/100\n",
      "4104/4104 [==============================] - 2s 529us/step - loss: 225.9307 - mean_squared_error: 1.3034 - mean_absolute_error: 0.8322 - val_loss: 67.3305 - val_mean_squared_error: 0.4556 - val_mean_absolute_error: 0.5315\n",
      "Epoch 2/100\n",
      "4104/4104 [==============================] - 2s 471us/step - loss: 24.5382 - mean_squared_error: 0.1028 - mean_absolute_error: 0.2375 - val_loss: 9.2092 - val_mean_squared_error: 0.1480 - val_mean_absolute_error: 0.3029\n",
      "Epoch 3/100\n",
      "4104/4104 [==============================] - 2s 462us/step - loss: 6.8121 - mean_squared_error: 0.0715 - mean_absolute_error: 0.1982 - val_loss: 7.1295 - val_mean_squared_error: 0.1165 - val_mean_absolute_error: 0.2725\n",
      "Epoch 4/100\n",
      "4104/4104 [==============================] - 2s 457us/step - loss: 6.3872 - mean_squared_error: 0.0377 - mean_absolute_error: 0.1491 - val_loss: 6.3959 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1230\n",
      "Epoch 5/100\n",
      "4104/4104 [==============================] - 2s 454us/step - loss: 6.3615 - mean_squared_error: 0.0233 - mean_absolute_error: 0.1192 - val_loss: 6.6959 - val_mean_squared_error: 0.0461 - val_mean_absolute_error: 0.1718\n",
      "Epoch 6/100\n",
      "4104/4104 [==============================] - 2s 461us/step - loss: 6.3632 - mean_squared_error: 0.0230 - mean_absolute_error: 0.1186 - val_loss: 6.4989 - val_mean_squared_error: 0.0269 - val_mean_absolute_error: 0.1298\n",
      "Epoch 7/100\n",
      "4104/4104 [==============================] - 2s 469us/step - loss: 6.3597 - mean_squared_error: 0.0222 - mean_absolute_error: 0.1169 - val_loss: 6.4178 - val_mean_squared_error: 0.0299 - val_mean_absolute_error: 0.1412\n",
      "Epoch 8/100\n",
      "4104/4104 [==============================] - 2s 462us/step - loss: 6.3603 - mean_squared_error: 0.0233 - mean_absolute_error: 0.1195 - val_loss: 6.4096 - val_mean_squared_error: 0.0227 - val_mean_absolute_error: 0.1220\n",
      "Epoch 9/100\n",
      "4104/4104 [==============================] - 2s 463us/step - loss: 6.3583 - mean_squared_error: 0.0221 - mean_absolute_error: 0.1164 - val_loss: 6.3845 - val_mean_squared_error: 0.0222 - val_mean_absolute_error: 0.1183\n",
      "Epoch 10/100\n",
      "4104/4104 [==============================] - 2s 480us/step - loss: 6.3575 - mean_squared_error: 0.0220 - mean_absolute_error: 0.1163 - val_loss: 7.0413 - val_mean_squared_error: 0.1722 - val_mean_absolute_error: 0.2716\n",
      "Epoch 11/100\n",
      "4104/4104 [==============================] - 2s 456us/step - loss: 6.3630 - mean_squared_error: 0.0248 - mean_absolute_error: 0.1193 - val_loss: 6.4484 - val_mean_squared_error: 0.0415 - val_mean_absolute_error: 0.1511\n",
      "Epoch 12/100\n",
      "4104/4104 [==============================] - 2s 461us/step - loss: 6.3579 - mean_squared_error: 0.0220 - mean_absolute_error: 0.1168 - val_loss: 6.4544 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.1185\n",
      "Epoch 13/100\n",
      "4104/4104 [==============================] - 2s 466us/step - loss: 6.3573 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1161 - val_loss: 6.8173 - val_mean_squared_error: 0.0471 - val_mean_absolute_error: 0.1745\n",
      "Epoch 14/100\n",
      "4104/4104 [==============================] - 2s 471us/step - loss: 6.3593 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1156 - val_loss: 6.4247 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1252\n",
      "Epoch 15/100\n",
      "4104/4104 [==============================] - 2s 492us/step - loss: 6.3572 - mean_squared_error: 0.0218 - mean_absolute_error: 0.1159 - val_loss: 6.5069 - val_mean_squared_error: 0.0480 - val_mean_absolute_error: 0.1785\n",
      "Epoch 16/100\n",
      "4104/4104 [==============================] - 2s 459us/step - loss: 6.3573 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1149 - val_loss: 6.3868 - val_mean_squared_error: 0.0214 - val_mean_absolute_error: 0.1171\n",
      "Epoch 17/100\n",
      "4104/4104 [==============================] - 2s 469us/step - loss: 6.3570 - mean_squared_error: 0.0220 - mean_absolute_error: 0.1164 - val_loss: 6.4499 - val_mean_squared_error: 0.0287 - val_mean_absolute_error: 0.1332\n",
      "Epoch 18/100\n",
      "4104/4104 [==============================] - 2s 467us/step - loss: 6.3568 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1149 - val_loss: 6.4544 - val_mean_squared_error: 0.0230 - val_mean_absolute_error: 0.1215\n",
      "Epoch 19/100\n",
      "4104/4104 [==============================] - 2s 461us/step - loss: 6.3581 - mean_squared_error: 0.0225 - mean_absolute_error: 0.1181 - val_loss: 6.4209 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.1217\n",
      "Epoch 20/100\n",
      "4104/4104 [==============================] - 2s 456us/step - loss: 6.3567 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1153 - val_loss: 6.9293 - val_mean_squared_error: 0.1073 - val_mean_absolute_error: 0.2265\n",
      "Epoch 21/100\n",
      "4104/4104 [==============================] - 2s 455us/step - loss: 6.3604 - mean_squared_error: 0.0235 - mean_absolute_error: 0.1160 - val_loss: 6.7808 - val_mean_squared_error: 0.0370 - val_mean_absolute_error: 0.1539\n",
      "Epoch 22/100\n",
      "4104/4104 [==============================] - 2s 472us/step - loss: 6.3587 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1157 - val_loss: 6.9511 - val_mean_squared_error: 0.1244 - val_mean_absolute_error: 0.2193\n",
      "Epoch 23/100\n",
      "4104/4104 [==============================] - 2s 493us/step - loss: 6.3598 - mean_squared_error: 0.0224 - mean_absolute_error: 0.1168 - val_loss: 6.3902 - val_mean_squared_error: 0.0241 - val_mean_absolute_error: 0.1225\n",
      "Epoch 24/100\n",
      "4104/4104 [==============================] - 2s 479us/step - loss: 6.3559 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1153 - val_loss: 7.6928 - val_mean_squared_error: 0.0824 - val_mean_absolute_error: 0.2292\n",
      "Epoch 25/100\n",
      "4104/4104 [==============================] - 2s 455us/step - loss: 6.3658 - mean_squared_error: 0.0222 - mean_absolute_error: 0.1166 - val_loss: 6.4161 - val_mean_squared_error: 0.0301 - val_mean_absolute_error: 0.1365\n",
      "Epoch 26/100\n",
      "4104/4104 [==============================] - 2s 460us/step - loss: 6.3562 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1150 - val_loss: 6.5066 - val_mean_squared_error: 0.0337 - val_mean_absolute_error: 0.1462\n",
      "Epoch 27/100\n",
      "4104/4104 [==============================] - 2s 476us/step - loss: 6.3566 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1152 - val_loss: 6.6399 - val_mean_squared_error: 0.0479 - val_mean_absolute_error: 0.1794\n",
      "Epoch 28/100\n",
      "4104/4104 [==============================] - 2s 465us/step - loss: 6.3580 - mean_squared_error: 0.0219 - mean_absolute_error: 0.1160 - val_loss: 6.4349 - val_mean_squared_error: 0.0231 - val_mean_absolute_error: 0.1209\n",
      "Epoch 29/100\n",
      "4104/4104 [==============================] - 2s 463us/step - loss: 6.3562 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1148 - val_loss: 6.5108 - val_mean_squared_error: 0.0344 - val_mean_absolute_error: 0.1507\n",
      "Epoch 30/100\n",
      "4104/4104 [==============================] - 2s 462us/step - loss: 6.3568 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1151 - val_loss: 6.5948 - val_mean_squared_error: 0.0291 - val_mean_absolute_error: 0.1358\n",
      "Epoch 31/100\n",
      "4104/4104 [==============================] - 2s 464us/step - loss: 6.3574 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1153 - val_loss: 6.4451 - val_mean_squared_error: 0.0406 - val_mean_absolute_error: 0.1686\n",
      "Epoch 32/100\n",
      "4104/4104 [==============================] - 2s 468us/step - loss: 6.3570 - mean_squared_error: 0.0218 - mean_absolute_error: 0.1165 - val_loss: 6.4736 - val_mean_squared_error: 0.0333 - val_mean_absolute_error: 0.1449\n",
      "Epoch 33/100\n",
      "4104/4104 [==============================] - 2s 478us/step - loss: 6.3560 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1153 - val_loss: 6.4415 - val_mean_squared_error: 0.0375 - val_mean_absolute_error: 0.1596\n",
      "Epoch 34/100\n",
      "4104/4104 [==============================] - 2s 449us/step - loss: 6.3566 - mean_squared_error: 0.0220 - mean_absolute_error: 0.1157 - val_loss: 6.4331 - val_mean_squared_error: 0.0233 - val_mean_absolute_error: 0.1205\n",
      "Epoch 35/100\n",
      "4104/4104 [==============================] - 2s 458us/step - loss: 6.3557 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1146 - val_loss: 6.4212 - val_mean_squared_error: 0.0262 - val_mean_absolute_error: 0.1278\n",
      "Epoch 36/100\n",
      "4104/4104 [==============================] - 2s 457us/step - loss: 6.3559 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1150 - val_loss: 6.5947 - val_mean_squared_error: 0.0333 - val_mean_absolute_error: 0.1453\n",
      "Epoch 37/100\n",
      "4104/4104 [==============================] - 2s 454us/step - loss: 6.3565 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1141 - val_loss: 6.5056 - val_mean_squared_error: 0.0345 - val_mean_absolute_error: 0.1488\n",
      "Epoch 38/100\n",
      "4104/4104 [==============================] - 2s 460us/step - loss: 6.3569 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1156 - val_loss: 6.4032 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.1152\n",
      "Epoch 39/100\n",
      "4104/4104 [==============================] - 2s 464us/step - loss: 6.3555 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1153 - val_loss: 6.4582 - val_mean_squared_error: 0.0242 - val_mean_absolute_error: 0.1226\n",
      "Epoch 40/100\n",
      "4104/4104 [==============================] - 2s 461us/step - loss: 6.3562 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1137 - val_loss: 6.4742 - val_mean_squared_error: 0.0271 - val_mean_absolute_error: 0.1295\n",
      "Epoch 41/100\n",
      "4104/4104 [==============================] - 2s 438us/step - loss: 6.3561 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1150 - val_loss: 6.4222 - val_mean_squared_error: 0.0336 - val_mean_absolute_error: 0.1440\n",
      "Epoch 42/100\n",
      "4104/4104 [==============================] - 2s 433us/step - loss: 6.3560 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1155 - val_loss: 6.5128 - val_mean_squared_error: 0.0409 - val_mean_absolute_error: 0.1677\n",
      "Epoch 43/100\n",
      "4104/4104 [==============================] - 2s 432us/step - loss: 6.3564 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1158 - val_loss: 6.6399 - val_mean_squared_error: 0.0606 - val_mean_absolute_error: 0.1726\n",
      "Epoch 44/100\n",
      "4104/4104 [==============================] - 2s 443us/step - loss: 6.3569 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1143 - val_loss: 6.5480 - val_mean_squared_error: 0.0387 - val_mean_absolute_error: 0.1593\n",
      "Epoch 45/100\n",
      "4104/4104 [==============================] - 2s 430us/step - loss: 6.3562 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1158 - val_loss: 6.4807 - val_mean_squared_error: 0.0372 - val_mean_absolute_error: 0.1414\n",
      "Epoch 46/100\n",
      "4104/4104 [==============================] - 2s 437us/step - loss: 6.3553 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1136 - val_loss: 6.4172 - val_mean_squared_error: 0.0240 - val_mean_absolute_error: 0.1252\n",
      "Epoch 47/100\n",
      "4104/4104 [==============================] - 2s 444us/step - loss: 6.3551 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1145 - val_loss: 6.6527 - val_mean_squared_error: 0.0572 - val_mean_absolute_error: 0.1590\n",
      "Epoch 48/100\n",
      "4104/4104 [==============================] - 2s 440us/step - loss: 6.3566 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1152 - val_loss: 6.4784 - val_mean_squared_error: 0.0263 - val_mean_absolute_error: 0.1314\n",
      "Epoch 49/100\n",
      "4104/4104 [==============================] - 2s 460us/step - loss: 6.3554 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1150 - val_loss: 6.4179 - val_mean_squared_error: 0.0292 - val_mean_absolute_error: 0.1396\n",
      "Epoch 50/100\n",
      "4104/4104 [==============================] - 2s 456us/step - loss: 6.3555 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1157 - val_loss: 6.4390 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.1173\n",
      "Epoch 51/100\n",
      "4104/4104 [==============================] - 2s 444us/step - loss: 6.3554 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1147 - val_loss: 6.4357 - val_mean_squared_error: 0.0244 - val_mean_absolute_error: 0.1255\n",
      "Epoch 52/100\n",
      "4104/4104 [==============================] - 2s 446us/step - loss: 6.3550 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1142 - val_loss: 6.4911 - val_mean_squared_error: 0.0291 - val_mean_absolute_error: 0.1352\n",
      "Epoch 53/100\n",
      "4104/4104 [==============================] - 2s 426us/step - loss: 6.3553 - mean_squared_error: 0.0208 - mean_absolute_error: 0.1134 - val_loss: 6.4111 - val_mean_squared_error: 0.0231 - val_mean_absolute_error: 0.1224\n",
      "Epoch 54/100\n",
      "4104/4104 [==============================] - 2s 434us/step - loss: 6.3557 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1152 - val_loss: 6.5143 - val_mean_squared_error: 0.0293 - val_mean_absolute_error: 0.1325\n",
      "Epoch 55/100\n",
      "4104/4104 [==============================] - 2s 433us/step - loss: 6.3557 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1148 - val_loss: 6.4506 - val_mean_squared_error: 0.0309 - val_mean_absolute_error: 0.1440\n",
      "Epoch 56/100\n",
      "4104/4104 [==============================] - 2s 429us/step - loss: 6.3554 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1139 - val_loss: 6.5916 - val_mean_squared_error: 0.0694 - val_mean_absolute_error: 0.1883\n",
      "Epoch 57/100\n",
      "4104/4104 [==============================] - 2s 438us/step - loss: 6.3558 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1142 - val_loss: 6.4767 - val_mean_squared_error: 0.0433 - val_mean_absolute_error: 0.1479\n",
      "Epoch 58/100\n",
      "4104/4104 [==============================] - 2s 455us/step - loss: 6.3557 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1147 - val_loss: 6.4241 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.1189\n",
      "Epoch 59/100\n",
      "4104/4104 [==============================] - 2s 436us/step - loss: 6.3548 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1141 - val_loss: 6.4931 - val_mean_squared_error: 0.0273 - val_mean_absolute_error: 0.1307quared_error: 0.0208 - mean_\n",
      "Epoch 60/100\n",
      "4104/4104 [==============================] - 2s 431us/step - loss: 6.3554 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1139 - val_loss: 6.4786 - val_mean_squared_error: 0.0272 - val_mean_absolute_error: 0.1344\n",
      "Epoch 61/100\n",
      "4104/4104 [==============================] - 2s 451us/step - loss: 6.3551 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1137 - val_loss: 6.4285 - val_mean_squared_error: 0.0296 - val_mean_absolute_error: 0.1371\n",
      "Epoch 62/100\n",
      "4104/4104 [==============================] - 2s 429us/step - loss: 6.3552 - mean_squared_error: 0.0208 - mean_absolute_error: 0.1136 - val_loss: 6.5867 - val_mean_squared_error: 0.0259 - val_mean_absolute_error: 0.1279\n",
      "Epoch 63/100\n",
      "4104/4104 [==============================] - 2s 426us/step - loss: 6.3568 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1149 - val_loss: 6.6013 - val_mean_squared_error: 0.0292 - val_mean_absolute_error: 0.1355\n",
      "Epoch 64/100\n",
      "4104/4104 [==============================] - 2s 433us/step - loss: 6.3564 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1143 - val_loss: 6.5460 - val_mean_squared_error: 0.0263 - val_mean_absolute_error: 0.1303\n",
      "Epoch 65/100\n",
      "4104/4104 [==============================] - 2s 429us/step - loss: 6.3558 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1140 - val_loss: 6.4249 - val_mean_squared_error: 0.0251 - val_mean_absolute_error: 0.1246\n",
      "Epoch 66/100\n",
      "4104/4104 [==============================] - 2s 434us/step - loss: 6.3554 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1151 - val_loss: 6.4190 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.1225\n",
      "Epoch 67/100\n",
      "4104/4104 [==============================] - 2s 461us/step - loss: 6.3548 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1134 - val_loss: 6.5043 - val_mean_squared_error: 0.0248 - val_mean_absolute_error: 0.1231\n",
      "Epoch 68/100\n",
      "4104/4104 [==============================] - 2s 434us/step - loss: 6.3556 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1138 - val_loss: 6.4690 - val_mean_squared_error: 0.0236 - val_mean_absolute_error: 0.1218\n",
      "Epoch 69/100\n",
      "4104/4104 [==============================] - 2s 444us/step - loss: 6.3553 - mean_squared_error: 0.0214 - mean_absolute_error: 0.1146 - val_loss: 6.3551 - val_mean_squared_error: 0.0207 - val_mean_absolute_error: 0.1142\n",
      "Epoch 70/100\n",
      "4104/4104 [==============================] - 2s 444us/step - loss: 6.3541 - mean_squared_error: 0.0209 - mean_absolute_error: 0.1134 - val_loss: 6.4522 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.1177\n",
      "Epoch 71/100\n",
      "4104/4104 [==============================] - 2s 452us/step - loss: 6.3548 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1145 - val_loss: 6.4350 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1198\n",
      "Epoch 72/100\n",
      "4104/4104 [==============================] - 2s 438us/step - loss: 6.3546 - mean_squared_error: 0.0208 - mean_absolute_error: 0.1137 - val_loss: 6.5808 - val_mean_squared_error: 0.0337 - val_mean_absolute_error: 0.1417\n",
      "Epoch 73/100\n",
      "4104/4104 [==============================] - 2s 437us/step - loss: 6.3558 - mean_squared_error: 0.0213 - mean_absolute_error: 0.1147 - val_loss: 6.4097 - val_mean_squared_error: 0.0276 - val_mean_absolute_error: 0.1304\n",
      "Epoch 74/100\n",
      "4104/4104 [==============================] - 2s 435us/step - loss: 6.3544 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1143 - val_loss: 6.4925 - val_mean_squared_error: 0.0258 - val_mean_absolute_error: 0.1256\n",
      "Epoch 75/100\n",
      "4104/4104 [==============================] - 2s 446us/step - loss: 6.3549 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1136 - val_loss: 6.4356 - val_mean_squared_error: 0.0257 - val_mean_absolute_error: 0.1260\n",
      "Epoch 76/100\n",
      "4104/4104 [==============================] - 2s 465us/step - loss: 6.3551 - mean_squared_error: 0.0215 - mean_absolute_error: 0.1151 - val_loss: 6.4862 - val_mean_squared_error: 0.0312 - val_mean_absolute_error: 0.1434\n",
      "Epoch 77/100\n",
      "4104/4104 [==============================] - 2s 440us/step - loss: 6.3552 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1138 - val_loss: 6.5150 - val_mean_squared_error: 0.0372 - val_mean_absolute_error: 0.1535\n",
      "Epoch 78/100\n",
      "4104/4104 [==============================] - 2s 433us/step - loss: 6.3549 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1140 - val_loss: 6.4829 - val_mean_squared_error: 0.0424 - val_mean_absolute_error: 0.1678\n",
      "Epoch 79/100\n",
      "4104/4104 [==============================] - 2s 441us/step - loss: 6.3549 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1147 - val_loss: 6.4381 - val_mean_squared_error: 0.0251 - val_mean_absolute_error: 0.1286\n",
      "Epoch 80/100\n",
      "4104/4104 [==============================] - 2s 436us/step - loss: 6.3546 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1142 - val_loss: 6.4265 - val_mean_squared_error: 0.0217 - val_mean_absolute_error: 0.1138\n",
      "Epoch 81/100\n",
      "4104/4104 [==============================] - 2s 436us/step - loss: 6.3546 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1141 - val_loss: 6.5837 - val_mean_squared_error: 0.0347 - val_mean_absolute_error: 0.1489\n",
      "Epoch 82/100\n",
      "4104/4104 [==============================] - 2s 439us/step - loss: 6.3559 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1138 - val_loss: 6.3779 - val_mean_squared_error: 0.0195 - val_mean_absolute_error: 0.1110\n",
      "Epoch 83/100\n",
      "4104/4104 [==============================] - 2s 437us/step - loss: 6.3541 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1141 - val_loss: 6.3602 - val_mean_squared_error: 0.0221 - val_mean_absolute_error: 0.1183\n",
      "Epoch 84/100\n",
      "4104/4104 [==============================] - 2s 451us/step - loss: 6.3540 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1136 - val_loss: 6.4977 - val_mean_squared_error: 0.0437 - val_mean_absolute_error: 0.1511\n",
      "Epoch 85/100\n",
      "4104/4104 [==============================] - 2s 451us/step - loss: 6.3553 - mean_squared_error: 0.0217 - mean_absolute_error: 0.1145 - val_loss: 6.5604 - val_mean_squared_error: 0.0310 - val_mean_absolute_error: 0.1394\n",
      "Epoch 86/100\n",
      "4104/4104 [==============================] - 2s 440us/step - loss: 6.3547 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1140 - val_loss: 6.4425 - val_mean_squared_error: 0.0334 - val_mean_absolute_error: 0.1495\n",
      "Epoch 87/100\n",
      "4104/4104 [==============================] - 2s 441us/step - loss: 6.3544 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1141 - val_loss: 6.4373 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.1179\n",
      "Epoch 88/100\n",
      "4104/4104 [==============================] - 2s 436us/step - loss: 6.3543 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1138 - val_loss: 6.4467 - val_mean_squared_error: 0.0267 - val_mean_absolute_error: 0.1291\n",
      "Epoch 89/100\n",
      "4104/4104 [==============================] - 2s 433us/step - loss: 6.3541 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1134 - val_loss: 6.4805 - val_mean_squared_error: 0.0244 - val_mean_absolute_error: 0.1230\n",
      "Epoch 90/100\n",
      "4104/4104 [==============================] - 2s 438us/step - loss: 6.3545 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1137 - val_loss: 6.3870 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.1175\n",
      "Epoch 91/100\n",
      "4104/4104 [==============================] - 2s 435us/step - loss: 6.3540 - mean_squared_error: 0.0208 - mean_absolute_error: 0.1132 - val_loss: 6.3471 - val_mean_squared_error: 0.0204 - val_mean_absolute_error: 0.1121\n",
      "Epoch 92/100\n",
      "4104/4104 [==============================] - 2s 438us/step - loss: 6.3539 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1141 - val_loss: 6.4429 - val_mean_squared_error: 0.0282 - val_mean_absolute_error: 0.1330\n",
      "Epoch 93/100\n",
      "4104/4104 [==============================] - 2s 457us/step - loss: 6.3543 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1142 - val_loss: 6.4103 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1235\n",
      "Epoch 94/100\n",
      "4104/4104 [==============================] - 2s 463us/step - loss: 6.3538 - mean_squared_error: 0.0206 - mean_absolute_error: 0.1128 - val_loss: 7.3446 - val_mean_squared_error: 0.0629 - val_mean_absolute_error: 0.2000\n",
      "Epoch 95/100\n",
      "4104/4104 [==============================] - 2s 437us/step - loss: 6.3622 - mean_squared_error: 0.0216 - mean_absolute_error: 0.1155 - val_loss: 6.3782 - val_mean_squared_error: 0.0205 - val_mean_absolute_error: 0.1136\n",
      "Epoch 96/100\n",
      "4104/4104 [==============================] - 2s 459us/step - loss: 6.3537 - mean_squared_error: 0.0209 - mean_absolute_error: 0.1134 - val_loss: 6.8007 - val_mean_squared_error: 0.0392 - val_mean_absolute_error: 0.1600\n",
      "Epoch 97/100\n",
      "4104/4104 [==============================] - 2s 444us/step - loss: 6.3565 - mean_squared_error: 0.0212 - mean_absolute_error: 0.1140 - val_loss: 6.4310 - val_mean_squared_error: 0.0284 - val_mean_absolute_error: 0.1279\n",
      "Epoch 98/100\n",
      "4104/4104 [==============================] - 2s 455us/step - loss: 6.3540 - mean_squared_error: 0.0211 - mean_absolute_error: 0.1141 - val_loss: 6.8835 - val_mean_squared_error: 0.0714 - val_mean_absolute_error: 0.1798\n",
      "Epoch 99/100\n",
      "4104/4104 [==============================] - 2s 459us/step - loss: 6.3566 - mean_squared_error: 0.0219 - mean_absolute_error: 0.1138 - val_loss: 6.4079 - val_mean_squared_error: 0.0248 - val_mean_absolute_error: 0.1230\n",
      "Epoch 100/100\n",
      "4104/4104 [==============================] - 2s 443us/step - loss: 6.3531 - mean_squared_error: 0.0207 - mean_absolute_error: 0.1131 - val_loss: 6.3872 - val_mean_squared_error: 0.0196 - val_mean_absolute_error: 0.1105\n",
      "dict_keys(['val_loss', 'val_mean_squared_error', 'val_mean_absolute_error', 'loss', 'mean_squared_error', 'mean_absolute_error'])\n",
      "Test loss: [6.3872261205379495, 0.01957134381081858, 0.11047748120439913]\n",
      "Train loss: [6.389035813292565, 0.021380995195104828, 0.11478729718900331]\n",
      "Mean Squared Error of test:  0.019571345\n",
      "Mean Squared Error of train: 0.021380994\n",
      "Mean Absolute Error of test:  0.110477485\n",
      "Mean Absolute Error of train:  0.114787295\n",
      "Coefficient of Determination for test:  -0.02989795514728044\n",
      "Coefficient of Determination for train:  -0.0567515322168739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Linear Regression\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score\n",
    "from tensorflow import keras\n",
    "import pandas\n",
    "\n",
    "\n",
    "with open('datamrosbmd1103_B1THD', 'rb') as file_handler:\n",
    "    data = pickle.load(file_handler)\n",
    "    X, Y = data.get('X', []).values, data.get('Y', []).values\n",
    "\n",
    "\n",
    "def linear_regression():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1125, input_dim=1125, kernel_initializer='normal', activation='relu', kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(optimizer='RMSprop', loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def main(plot=True):\n",
    "    # fix random seed for reproducibility\n",
    "    # seed = 7\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "    # numpy.random.seed(seed)\n",
    "    # The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "    # rn.seed(seed)\n",
    "\n",
    "    # according to keras documentation, numpy seed should be set before importing keras\n",
    "    # information regarding setup for obtaining reproducible results using Keras during development in the following link https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
    "    # tf.set_random_seed(seed)\n",
    "\n",
    "    batch_size = 50\n",
    "    # num_classes = 1\n",
    "    # epochs = 50\n",
    "    number_of_data = X.shape[0]\n",
    "    number_of_train_data = int(.8 * number_of_data)\n",
    "    # number_of_test_data = number_of_data - number_of_train_data\n",
    "\n",
    "    # load dataset\n",
    "    x_train, x_test = X[:number_of_train_data, :], X[number_of_train_data:, :]\n",
    "#     mean_train_data = numpy.mean(train_data, axis=0)\n",
    "#     std_train_data = numpy.std(train_data, axis=0)\n",
    "#     x_train = (train_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "#     x_test = (test_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "    y_train, y_test = Y[:number_of_train_data], Y[number_of_train_data:]\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "\n",
    "    model = linear_regression()\n",
    "    # history = model.fit(x_train, y_train, batch_size=batch_size, epochs=3, verbose=1, validation_data=(x_test, y_test))\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, verbose=1, epochs=100, validation_data=(x_test, y_test))\n",
    "    print(history.history.keys())\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score)\n",
    "\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    print('Train loss:', score)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    print('Mean Squared Error of test: ', mean_squared_error(y_test, y_pred))\n",
    "    print('Mean Squared Error of train:', mean_squared_error(y_train, model.predict(x_train)))\n",
    "\n",
    "    print('Mean Absolute Error of test: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Absolute Error of train: ', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "\n",
    "    print('Coefficient of Determination for test: ', r2_score(y_test, y_pred))\n",
    "    print('Coefficient of Determination for train: ', r2_score(y_train, model.predict(x_train)))\n",
    "\n",
    "    if not plot:\n",
    "        return history.history['loss'], history.history['val_loss']\n",
    "    pyplot.plot(history.history['loss'], 'b-')\n",
    "    pyplot.plot(history.history['val_loss'], 'r-')\n",
    "    pyplot.title('Mean Squared Error Loss: Linear Regression for Total Hip BMD')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['Train Data', 'Test Data'], loc='upper right')\n",
    "    pyplot.savefig('reg_B1THD_MSE')\n",
    "    pyplot.show()\n",
    "\n",
    "    # Plot the predicted value against the actual value\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.scatter(y_test, y_pred)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_pred.min(), y_pred.max()], 'k--', lw=4)\n",
    "    pyplot.title('Scatter plot of Measured vs. Predicted : Linear Regression for Total Hip BMD')\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    pyplot.savefig('reg_B1THD_scatter')\n",
    "    pyplot.show()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01798431309204622  SOE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n",
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:737: UserWarning: Some inputs do not have OOB scores. This probably means too few trees were used to compute any reliable oob estimates.\n",
      "  warn(\"Some inputs do not have OOB scores. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error of test:  0.01798431309204622\n",
      "Mean Square Error of train:  0.0183181438953865\n",
      "Mean Absolute Error of test:  0.10613226064573457\n",
      "Mean Absolute Error of train:  0.10658802210241503\n",
      "Coefficient of Determination for test:  0.05361595552114573\n",
      "Coefficient of Determination for train:  0.09462928670549298\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "with open('datamrosbmd1103_B1THD', 'rb') as file_handler:\n",
    "    data = pickle.load(file_handler)\n",
    "    X, Y = data.get('X', []).values, data.get('Y', []).values\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "# seed = 7\n",
    "\n",
    "# The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "# numpy.random.seed(seed)\n",
    "# The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "# random.seed(seed)\n",
    "\n",
    "# The below tensorflow.set_random_seed() will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
    "# tensorflow.set_random_seed(seed)\n",
    "# Y = label_binarize(Y, classes=[0,1])\n",
    "\n",
    "batch_size = 120\n",
    "num_classes = 2\n",
    "\n",
    "number_of_data = X.shape[0]\n",
    "number_of_train_data = int(.8 * number_of_data)\n",
    "number_of_test_data = number_of_data - number_of_train_data\n",
    "\n",
    "x_train, x_test = X[:number_of_train_data, :], X[number_of_train_data:, :]\n",
    "# mean_train_data = numpy.mean(train_data, axis=0)\n",
    "# std_train_data = numpy.std(train_data, axis=0)\n",
    "# x_train = (train_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "# x_test = (test_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "y_train, y_test = Y[:number_of_train_data], Y[number_of_train_data:]\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "n_estimators = 100\n",
    "\n",
    "\n",
    "# override the RandomForestRegressor library\n",
    "class RandomForestRegressorCustom(RandomForestRegressor):\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        \"\"\"Returns the coefficient of determination R^2 of the prediction.\n",
    "\n",
    "        The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
    "        The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = (n_samples, n_features)\n",
    "            Test samples. For some estimators this may be a precomputed kernel matrix instead, shape = (n_samples, n_samples_fitted], where n_samples_fitted is the number of samples used in the fitting for the estimator.\n",
    "\n",
    "        y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
    "            True values for X.\n",
    "\n",
    "        sample_weight : array-like, shape = [n_samples], optional\n",
    "            Sample weights.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            R^2 of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "\n",
    "        return mean_squared_error(y, self.predict(X))\n",
    "\n",
    "\n",
    "def create_model(epoch):\n",
    "    return RandomForestRegressorCustom(n_estimators=epoch, random_state = 42, warm_start=True, oob_score=True, max_features='sqrt', max_depth=4)\n",
    "\n",
    "\n",
    "def main(plot=True):\n",
    "    epoch = 100\n",
    "    model = create_model(epoch)\n",
    "    model.fit(x_train, y_train)\n",
    "    model.score(x_test, y_test)\n",
    "    print(model.score(x_test, y_test), ' SOE')\n",
    "\n",
    "    train_score, test_score = [], []\n",
    "\n",
    "    for i in range(epoch):\n",
    "        model = create_model(i + 1)\n",
    "        model.fit(x_train, y_train)\n",
    "        train_score.append(model.score(x_train, y_train))\n",
    "        test_score.append(model.score(x_test, y_test))\n",
    "#     print(test_score, ' TEST SCORE')\n",
    "#     print(train_score, ' TRAIN SCORE')\n",
    "\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_)\n",
    "    feature_importances.to_csv('feature_importances_THBMD.csv')\n",
    "    \n",
    "    print('Mean Square Error of test: ', mean_squared_error(y_test, model.predict(x_test)))\n",
    "    print('Mean Square Error of train: ', mean_squared_error(y_train, model.predict(x_train)))\n",
    "\n",
    "    print('Mean Absolute Error of test: ', mean_absolute_error(y_test, model.predict(x_test)))\n",
    "    print('Mean Absolute Error of train: ', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "    \n",
    "    print('Coefficient of Determination for test: ', r2_score(y_test, model.predict(x_test)))\n",
    "    print('Coefficient of Determination for train: ', r2_score(y_train, model.predict(x_train)))\n",
    "\n",
    "    if not plot:\n",
    "        return train_score, test_score\n",
    "    pyplot.plot(range(epoch), train_score, 'b-')\n",
    "    pyplot.plot(range(epoch), test_score, 'r-')\n",
    "    pyplot.title('Mean Squared Error Loss: Random Forest Regression for Total Hip BMD')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['Train Data', 'Test Data'], loc='upper right')\n",
    "    pyplot.savefig('rf_B1THD_MSE')\n",
    "    pyplot.show()\n",
    "\n",
    "    # Plot the predicted value against the actual value\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.scatter(y_test, model.predict(x_test))\n",
    "    ax.plot([y_test.min(), y_test.max()], [model.predict(x_test).min(), model.predict(x_test).max()], 'k--', lw=4)\n",
    "    pyplot.title('Scatter plot of Measured vs. Predicted : Random Forest for Total Hip BMD')\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    pyplot.savefig('rf_B1THD_scatter')\n",
    "    pyplot.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   30.7s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   30.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:   30.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1853151  0.17349005 0.16904581]  ALL TRY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01220796 0.0077525  0.18576158 ... 0.00056105 0.00029874 0.00030618]\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=1, warm_start=False)  HISTORY\n",
      "Mean Square Error of test:  0.016132791958981617\n",
      "Mean Square Error of train:  0.015950768330797806\n",
      "Mean Absolute Error of test:  0.09995651388132251\n",
      "Mean Absolute Error of train:  0.09982202388354655\n",
      "Coefficient of Determination for test:  0.1510480925941322\n",
      "Coefficient of Determination for train:  0.21163636535866714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "import pickle\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "with open('datamrosbmd1103_B1THD', 'rb') as file_handler:\n",
    "    data = pickle.load(file_handler)\n",
    "    X, Y = data.get('X', []).values, data.get('Y', []).values\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    return RandomForestRegressor(n_estimators=100, verbose=1)\n",
    "\n",
    "\n",
    "def main(plot=True):\n",
    "    # fix random seed for reproducibility\n",
    "    # seed = 7\n",
    "    # The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "    # numpy.random.seed(seed)\n",
    "    # The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "    # random.seed(seed)\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
    "    # tf.set_random_seed(seed)\n",
    "    # Y = label_binarize(Y, classes=[0,1])\n",
    "\n",
    "    # batch_size = 120\n",
    "    # num_classes = 2\n",
    "    # epochs = 15\n",
    "\n",
    "    number_of_data = X.shape[0]\n",
    "    number_of_train_data = int(.8 * number_of_data)\n",
    "    # number_of_test_data = number_of_data - number_of_train_data\n",
    "\n",
    "    # load dataset for MLP\n",
    "    x_train, x_test = X[:number_of_train_data, :], X[number_of_train_data:, :]\n",
    "#     mean_train_data = numpy.mean(train_data, axis=0)\n",
    "#     std_train_data = numpy.std(train_data, axis=0)\n",
    "#     x_train = (train_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "#     x_test = (test_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "    y_train, y_test = Y[:number_of_train_data], Y[number_of_train_data:]\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    validatescores = cross_val_score(model, x_train, y_train)\n",
    "    print(validatescores, ' ALL TRY')\n",
    "\n",
    "    history = model.fit(x_train, y_train)\n",
    "    print(history.feature_importances_)\n",
    "    print(history, ' HISTORY')\n",
    "    # y_pred = model.predict(x_test)\n",
    "\n",
    "    params = {'n_estimators': 100, 'max_depth': 4, 'min_samples_split': 2, 'learning_rate': 0.01, 'loss': 'ls'}\n",
    "    gbr = GradientBoostingRegressor(**params)\n",
    "    gbr.fit(x_train, y_train)\n",
    "\n",
    "    test_score = numpy.zeros((params['n_estimators'],), dtype=numpy.float64)\n",
    "    mse = mean_squared_error(y_test, gbr.predict(x_test))\n",
    "\n",
    "    print('Mean Square Error of test: ', mean_squared_error(y_test, gbr.predict(x_test)))\n",
    "    print('Mean Square Error of train: ', mean_squared_error(y_train, gbr.predict(x_train)))\n",
    "\n",
    "    print('Mean Absolute Error of test: ', mean_absolute_error(y_test, gbr.predict(x_test)))\n",
    "    print('Mean Absolute Error of train: ', mean_absolute_error(y_train, gbr.predict(x_train)))\n",
    "    \n",
    "    print('Coefficient of Determination for test: ', r2_score(y_test, gbr.predict(x_test)))\n",
    "    print('Coefficient of Determination for train: ', r2_score(y_train, gbr.predict(x_train)))\n",
    "\n",
    "    for i, y_pred in enumerate(gbr.staged_predict(x_test)):\n",
    "        test_score[i] = gbr.loss_(y_test, y_pred)\n",
    "    if not plot:\n",
    "        return gbr.train_score_, test_score\n",
    "    pyplot.figure()\n",
    "    pyplot.title('Mean Square Error Loss: Gradient Boosting for Total Hip BMD')\n",
    "    pyplot.plot(numpy.arange(params['n_estimators']) + 1, gbr.train_score_, 'b-', label='Training')\n",
    "    pyplot.plot(numpy.arange(params['n_estimators']) + 1, test_score, 'r-', label='Test')\n",
    "    pyplot.legend(loc='upper right')\n",
    "    pyplot.legend(loc='upper right')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.ylabel('Loss')\n",
    "    pyplot.savefig('gb_B1THD_MSE')\n",
    "    pyplot.show()\n",
    "\n",
    "    # Plot the predicted value against the actual value\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.scatter(y_test, y_pred)\n",
    "    ax.plot([y_test.min(), y_test.max()], [gbr.predict(x_test).min(), gbr.predict(x_test).max()], 'k--', lw=4)\n",
    "    pyplot.title('Scatter plot of Measured vs. Predicted : Gradient Boosting for Total Hip BMD')\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    pyplot.savefig('gb_B1THD_scatter')\n",
    "    pyplot.show()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1101 13:46:21.355010  6672 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1101 13:46:21.357007  6672 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "W1101 13:46:21.382935  6672 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W1101 13:46:21.461723  6672 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W1101 13:46:21.516577  6672 deprecation_wrapper.py:119] From C:\\Users\\jungj7\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (4104, 1125)\n",
      "4104 train samples\n",
      "1026 test samples\n",
      "Train on 4104 samples, validate on 1026 samples\n",
      "Epoch 1/100\n",
      "4104/4104 [==============================] - 3s 804us/step - loss: 266.9049 - mean_squared_error: 0.9321 - mean_absolute_error: 0.5888 - val_loss: 78.6720 - val_mean_squared_error: 0.0568 - val_mean_absolute_error: 0.1906\n",
      "Epoch 2/100\n",
      "4104/4104 [==============================] - 3s 741us/step - loss: 27.4060 - mean_squared_error: 0.0473 - mean_absolute_error: 0.1743 - val_loss: 4.9785 - val_mean_squared_error: 0.0422 - val_mean_absolute_error: 0.1635\n",
      "Epoch 3/100\n",
      "4104/4104 [==============================] - 3s 768us/step - loss: 2.5358 - mean_squared_error: 0.0266 - mean_absolute_error: 0.1266 - val_loss: 1.6651 - val_mean_squared_error: 0.0210 - val_mean_absolute_error: 0.1135\n",
      "Epoch 4/100\n",
      "4104/4104 [==============================] - 3s 800us/step - loss: 1.5670 - mean_squared_error: 0.0209 - mean_absolute_error: 0.1132 - val_loss: 1.5582 - val_mean_squared_error: 0.0204 - val_mean_absolute_error: 0.1141\n",
      "Epoch 5/100\n",
      "4104/4104 [==============================] - 3s 817us/step - loss: 1.5354 - mean_squared_error: 0.0206 - mean_absolute_error: 0.1126 - val_loss: 1.6341 - val_mean_squared_error: 0.0374 - val_mean_absolute_error: 0.1397\n",
      "Epoch 6/100\n",
      "4104/4104 [==============================] - 3s 757us/step - loss: 1.5571 - mean_squared_error: 0.0210 - mean_absolute_error: 0.1137 - val_loss: 1.5454 - val_mean_squared_error: 0.0206 - val_mean_absolute_error: 0.1123\n",
      "Epoch 7/100\n",
      "4104/4104 [==============================] - 3s 768us/step - loss: 1.5405 - mean_squared_error: 0.0202 - mean_absolute_error: 0.1114 - val_loss: 1.5644 - val_mean_squared_error: 0.0208 - val_mean_absolute_error: 0.1131\n",
      "Epoch 8/100\n",
      "4104/4104 [==============================] - 3s 752us/step - loss: 1.5428 - mean_squared_error: 0.0200 - mean_absolute_error: 0.1113 - val_loss: 1.6121 - val_mean_squared_error: 0.0257 - val_mean_absolute_error: 0.1278\n",
      "Epoch 9/100\n",
      "4104/4104 [==============================] - 3s 782us/step - loss: 1.5557 - mean_squared_error: 0.0203 - mean_absolute_error: 0.1115 - val_loss: 1.5930 - val_mean_squared_error: 0.0207 - val_mean_absolute_error: 0.1132\n",
      "Epoch 10/100\n",
      "4104/4104 [==============================] - 3s 773us/step - loss: 1.5482 - mean_squared_error: 0.0194 - mean_absolute_error: 0.1093 - val_loss: 1.5374 - val_mean_squared_error: 0.0186 - val_mean_absolute_error: 0.1078\n",
      "Epoch 11/100\n",
      "4104/4104 [==============================] - 3s 780us/step - loss: 1.5327 - mean_squared_error: 0.0187 - mean_absolute_error: 0.1073 - val_loss: 1.5706 - val_mean_squared_error: 0.0181 - val_mean_absolute_error: 0.1066\n",
      "Epoch 12/100\n",
      "4104/4104 [==============================] - 3s 776us/step - loss: 1.5391 - mean_squared_error: 0.0183 - mean_absolute_error: 0.1061 - val_loss: 1.5486 - val_mean_squared_error: 0.0184 - val_mean_absolute_error: 0.1068\n",
      "Epoch 13/100\n",
      "4104/4104 [==============================] - 3s 778us/step - loss: 1.5357 - mean_squared_error: 0.0185 - mean_absolute_error: 0.1063 - val_loss: 1.5363 - val_mean_squared_error: 0.0184 - val_mean_absolute_error: 0.1059\n",
      "Epoch 14/100\n",
      "4104/4104 [==============================] - 3s 776us/step - loss: 1.5297 - mean_squared_error: 0.0180 - mean_absolute_error: 0.1056 - val_loss: 1.5445 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1063\n",
      "Epoch 15/100\n",
      "4104/4104 [==============================] - 3s 810us/step - loss: 1.5311 - mean_squared_error: 0.0176 - mean_absolute_error: 0.1042 - val_loss: 1.5786 - val_mean_squared_error: 0.0186 - val_mean_absolute_error: 0.1089\n",
      "Epoch 16/100\n",
      "4104/4104 [==============================] - 3s 801us/step - loss: 1.5422 - mean_squared_error: 0.0180 - mean_absolute_error: 0.1052 - val_loss: 1.5681 - val_mean_squared_error: 0.0183 - val_mean_absolute_error: 0.1062\n",
      "Epoch 17/100\n",
      "4104/4104 [==============================] - 3s 805us/step - loss: 1.5367 - mean_squared_error: 0.0179 - mean_absolute_error: 0.1050 - val_loss: 1.5942 - val_mean_squared_error: 0.0208 - val_mean_absolute_error: 0.1127\n",
      "Epoch 18/100\n",
      "4104/4104 [==============================] - 3s 757us/step - loss: 1.5439 - mean_squared_error: 0.0180 - mean_absolute_error: 0.1050 - val_loss: 1.5375 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1052\n",
      "Epoch 19/100\n",
      "4104/4104 [==============================] - 3s 769us/step - loss: 1.5230 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1031 - val_loss: 1.5352 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.1012\n",
      "Epoch 20/100\n",
      "4104/4104 [==============================] - 3s 767us/step - loss: 1.5219 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1026 - val_loss: 1.5246 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.1006\n",
      "Epoch 21/100\n",
      "4104/4104 [==============================] - 3s 803us/step - loss: 1.5177 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1028 - val_loss: 1.5531 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.1032\n",
      "Epoch 22/100\n",
      "4104/4104 [==============================] - 3s 760us/step - loss: 1.5263 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1037 - val_loss: 1.5774 - val_mean_squared_error: 0.0211 - val_mean_absolute_error: 0.1145\n",
      "Epoch 23/100\n",
      "4104/4104 [==============================] - 3s 767us/step - loss: 1.5325 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1042 - val_loss: 1.5391 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.1050\n",
      "Epoch 24/100\n",
      "4104/4104 [==============================] - 3s 784us/step - loss: 1.5205 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1043 - val_loss: 1.5240 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.1006\n",
      "Epoch 25/100\n",
      "4104/4104 [==============================] - 3s 771us/step - loss: 1.5133 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.5407 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.1016\n",
      "Epoch 26/100\n",
      "4104/4104 [==============================] - 3s 785us/step - loss: 1.5211 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1031 - val_loss: 1.5200 - val_mean_squared_error: 0.0177 - val_mean_absolute_error: 0.1039\n",
      "Epoch 27/100\n",
      "4104/4104 [==============================] - 3s 793us/step - loss: 1.5108 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1030 - val_loss: 1.5102 - val_mean_squared_error: 0.0165 - val_mean_absolute_error: 0.1013\n",
      "Epoch 28/100\n",
      "4104/4104 [==============================] - 3s 776us/step - loss: 1.5062 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1026 - val_loss: 1.5717 - val_mean_squared_error: 0.0183 - val_mean_absolute_error: 0.1077\n",
      "Epoch 29/100\n",
      "4104/4104 [==============================] - 3s 781us/step - loss: 1.5276 - mean_squared_error: 0.0182 - mean_absolute_error: 0.1062 - val_loss: 1.5448 - val_mean_squared_error: 0.0179 - val_mean_absolute_error: 0.1079\n",
      "Epoch 30/100\n",
      "4104/4104 [==============================] - 3s 764us/step - loss: 1.5163 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1036 - val_loss: 1.5519 - val_mean_squared_error: 0.0209 - val_mean_absolute_error: 0.1101\n",
      "Epoch 31/100\n",
      "4104/4104 [==============================] - 3s 754us/step - loss: 1.5135 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1040 - val_loss: 1.5165 - val_mean_squared_error: 0.0167 - val_mean_absolute_error: 0.1011\n",
      "Epoch 32/100\n",
      "4104/4104 [==============================] - 3s 801us/step - loss: 1.5029 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1029 - val_loss: 1.5075 - val_mean_squared_error: 0.0177 - val_mean_absolute_error: 0.1041\n",
      "Epoch 33/100\n",
      "4104/4104 [==============================] - 3s 793us/step - loss: 1.4960 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1024 - val_loss: 1.5037 - val_mean_squared_error: 0.0163 - val_mean_absolute_error: 0.1009\n",
      "Epoch 34/100\n",
      "4104/4104 [==============================] - 3s 804us/step - loss: 1.4978 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1033 - val_loss: 1.5135 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.1018\n",
      "Epoch 35/100\n",
      "4104/4104 [==============================] - 3s 791us/step - loss: 1.5020 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.4917 - val_mean_squared_error: 0.0160 - val_mean_absolute_error: 0.0991\n",
      "Epoch 36/100\n",
      "4104/4104 [==============================] - 3s 774us/step - loss: 1.4918 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1022 - val_loss: 1.5046 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.1039\n",
      "Epoch 37/100\n",
      "4104/4104 [==============================] - 3s 786us/step - loss: 1.4971 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1019 - val_loss: 1.5103 - val_mean_squared_error: 0.0171 - val_mean_absolute_error: 0.1032\n",
      "Epoch 38/100\n",
      "4104/4104 [==============================] - 3s 794us/step - loss: 1.4973 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1030 - val_loss: 1.5025 - val_mean_squared_error: 0.0162 - val_mean_absolute_error: 0.1003\n",
      "Epoch 39/100\n",
      "4104/4104 [==============================] - 3s 780us/step - loss: 1.4946 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.4881 - val_mean_squared_error: 0.0160 - val_mean_absolute_error: 0.0993\n",
      "Epoch 40/100\n",
      "4104/4104 [==============================] - 3s 766us/step - loss: 1.4872 - mean_squared_error: 0.0168 - mean_absolute_error: 0.1015 - val_loss: 1.4988 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.1012\n",
      "Epoch 41/100\n",
      "4104/4104 [==============================] - 3s 788us/step - loss: 1.4920 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1029 - val_loss: 1.5106 - val_mean_squared_error: 0.0201 - val_mean_absolute_error: 0.1109\n",
      "Epoch 42/100\n",
      "4104/4104 [==============================] - 3s 776us/step - loss: 1.4961 - mean_squared_error: 0.0176 - mean_absolute_error: 0.1044 - val_loss: 1.4934 - val_mean_squared_error: 0.0173 - val_mean_absolute_error: 0.1029\n",
      "Epoch 43/100\n",
      "4104/4104 [==============================] - 3s 782us/step - loss: 1.4848 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1021 - val_loss: 1.4860 - val_mean_squared_error: 0.0158 - val_mean_absolute_error: 0.0986\n",
      "Epoch 44/100\n",
      "4104/4104 [==============================] - 3s 806us/step - loss: 1.4855 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1025 - val_loss: 1.4987 - val_mean_squared_error: 0.0187 - val_mean_absolute_error: 0.1086\n",
      "Epoch 45/100\n",
      "4104/4104 [==============================] - 3s 739us/step - loss: 1.4895 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1032 - val_loss: 1.5026 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.1018\n",
      "Epoch 46/100\n",
      "4104/4104 [==============================] - 3s 799us/step - loss: 1.4913 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1026 - val_loss: 1.4898 - val_mean_squared_error: 0.0154 - val_mean_absolute_error: 0.0976\n",
      "Epoch 47/100\n",
      "4104/4104 [==============================] - 3s 770us/step - loss: 1.4818 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1022 - val_loss: 1.4943 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.1013\n",
      "Epoch 48/100\n",
      "4104/4104 [==============================] - 3s 788us/step - loss: 1.4849 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1021 - val_loss: 1.4830 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.1022\n",
      "Epoch 49/100\n",
      "4104/4104 [==============================] - 3s 779us/step - loss: 1.4773 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1029 - val_loss: 1.4941 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.1062\n",
      "Epoch 50/100\n",
      "4104/4104 [==============================] - 3s 764us/step - loss: 1.4851 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1032 - val_loss: 1.4812 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.1015\n",
      "Epoch 51/100\n",
      "4104/4104 [==============================] - 3s 766us/step - loss: 1.4773 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1025 - val_loss: 1.4849 - val_mean_squared_error: 0.0167 - val_mean_absolute_error: 0.1009\n",
      "Epoch 52/100\n",
      "4104/4104 [==============================] - 3s 765us/step - loss: 1.4770 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1029 - val_loss: 1.4785 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.1015\n",
      "Epoch 53/100\n",
      "4104/4104 [==============================] - 3s 750us/step - loss: 1.4734 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1031 - val_loss: 1.4761 - val_mean_squared_error: 0.0156 - val_mean_absolute_error: 0.0996\n",
      "Epoch 54/100\n",
      "4104/4104 [==============================] - 3s 775us/step - loss: 1.4735 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1026 - val_loss: 1.4717 - val_mean_squared_error: 0.0159 - val_mean_absolute_error: 0.0998\n",
      "Epoch 55/100\n",
      "4104/4104 [==============================] - 3s 784us/step - loss: 1.4691 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1016 - val_loss: 1.4706 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.1020\n",
      "Epoch 56/100\n",
      "4104/4104 [==============================] - 3s 774us/step - loss: 1.4662 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.4728 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.1024\n",
      "Epoch 57/100\n",
      "4104/4104 [==============================] - 3s 786us/step - loss: 1.4683 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1028 - val_loss: 1.4752 - val_mean_squared_error: 0.0165 - val_mean_absolute_error: 0.1017\n",
      "Epoch 58/100\n",
      "4104/4104 [==============================] - 3s 785us/step - loss: 1.4699 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.4777 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.1051\n",
      "Epoch 59/100\n",
      "4104/4104 [==============================] - 3s 788us/step - loss: 1.4684 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1030 - val_loss: 1.4699 - val_mean_squared_error: 0.0160 - val_mean_absolute_error: 0.0996\n",
      "Epoch 60/100\n",
      "4104/4104 [==============================] - 3s 766us/step - loss: 1.4650 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1024 - val_loss: 1.4759 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.0993\n",
      "Epoch 61/100\n",
      "4104/4104 [==============================] - 3s 744us/step - loss: 1.4680 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1031 - val_loss: 1.4778 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.1025\n",
      "Epoch 62/100\n",
      "4104/4104 [==============================] - 3s 738us/step - loss: 1.4675 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1035 - val_loss: 1.4819 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1079\n",
      "Epoch 63/100\n",
      "4104/4104 [==============================] - 3s 725us/step - loss: 1.4681 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1036 - val_loss: 1.4709 - val_mean_squared_error: 0.0171 - val_mean_absolute_error: 0.1018\n",
      "Epoch 64/100\n",
      "4104/4104 [==============================] - 3s 744us/step - loss: 1.4627 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1035 - val_loss: 1.4660 - val_mean_squared_error: 0.0160 - val_mean_absolute_error: 0.1001\n",
      "Epoch 65/100\n",
      "4104/4104 [==============================] - 3s 730us/step - loss: 1.4587 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1027 - val_loss: 1.4634 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.1013\n",
      "Epoch 66/100\n",
      "4104/4104 [==============================] - 3s 734us/step - loss: 1.4609 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1028 - val_loss: 1.4559 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.0997\n",
      "Epoch 67/100\n",
      "4104/4104 [==============================] - 3s 758us/step - loss: 1.4547 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1036 - val_loss: 1.4620 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.1009\n",
      "Epoch 68/100\n",
      "4104/4104 [==============================] - 3s 733us/step - loss: 1.4538 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1028 - val_loss: 1.4491 - val_mean_squared_error: 0.0156 - val_mean_absolute_error: 0.0993\n",
      "Epoch 69/100\n",
      "4104/4104 [==============================] - 3s 732us/step - loss: 1.4493 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1028 - val_loss: 1.4552 - val_mean_squared_error: 0.0162 - val_mean_absolute_error: 0.1005\n",
      "Epoch 70/100\n",
      "4104/4104 [==============================] - 3s 723us/step - loss: 1.4498 - mean_squared_error: 0.0168 - mean_absolute_error: 0.1018 - val_loss: 1.4457 - val_mean_squared_error: 0.0163 - val_mean_absolute_error: 0.1012\n",
      "Epoch 71/100\n",
      "4104/4104 [==============================] - 3s 740us/step - loss: 1.4444 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.4509 - val_mean_squared_error: 0.0160 - val_mean_absolute_error: 0.0997\n",
      "Epoch 72/100\n",
      "4104/4104 [==============================] - 3s 766us/step - loss: 1.4465 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1018 - val_loss: 1.4654 - val_mean_squared_error: 0.0165 - val_mean_absolute_error: 0.1018\n",
      "Epoch 73/100\n",
      "4104/4104 [==============================] - 3s 753us/step - loss: 1.4554 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1036 - val_loss: 1.4677 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.1010\n",
      "Epoch 74/100\n",
      "4104/4104 [==============================] - 3s 765us/step - loss: 1.4647 - mean_squared_error: 0.0183 - mean_absolute_error: 0.1038 - val_loss: 1.4554 - val_mean_squared_error: 0.0157 - val_mean_absolute_error: 0.0993\n",
      "Epoch 75/100\n",
      "4104/4104 [==============================] - 3s 760us/step - loss: 1.4488 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1030 - val_loss: 1.4376 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.1006\n",
      "Epoch 76/100\n",
      "4104/4104 [==============================] - 3s 740us/step - loss: 1.4408 - mean_squared_error: 0.0173 - mean_absolute_error: 0.1033 - val_loss: 1.4409 - val_mean_squared_error: 0.0163 - val_mean_absolute_error: 0.1006\n",
      "Epoch 77/100\n",
      "4104/4104 [==============================] - 3s 786us/step - loss: 1.4382 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1024 - val_loss: 1.4364 - val_mean_squared_error: 0.0167 - val_mean_absolute_error: 0.1003\n",
      "Epoch 78/100\n",
      "4104/4104 [==============================] - 3s 807us/step - loss: 1.4373 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1026 - val_loss: 1.4463 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.1012\n",
      "Epoch 79/100\n",
      "4104/4104 [==============================] - 3s 820us/step - loss: 1.4408 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1030 - val_loss: 1.4432 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.1048\n",
      "Epoch 80/100\n",
      "4104/4104 [==============================] - 3s 814us/step - loss: 1.4390 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1037 - val_loss: 1.4323 - val_mean_squared_error: 0.0164 - val_mean_absolute_error: 0.1005\n",
      "Epoch 81/100\n",
      "4104/4104 [==============================] - 3s 814us/step - loss: 1.4310 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1027 - val_loss: 1.4452 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.1025\n",
      "Epoch 82/100\n",
      "4104/4104 [==============================] - 3s 804us/step - loss: 1.4384 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1029 - val_loss: 1.4351 - val_mean_squared_error: 0.0157 - val_mean_absolute_error: 0.0991\n",
      "Epoch 83/100\n",
      "4104/4104 [==============================] - 3s 751us/step - loss: 1.4307 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1021 - val_loss: 1.4324 - val_mean_squared_error: 0.0158 - val_mean_absolute_error: 0.0988\n",
      "Epoch 84/100\n",
      "4104/4104 [==============================] - 3s 749us/step - loss: 1.4349 - mean_squared_error: 0.0175 - mean_absolute_error: 0.1038 - val_loss: 1.4324 - val_mean_squared_error: 0.0162 - val_mean_absolute_error: 0.0997\n",
      "Epoch 85/100\n",
      "4104/4104 [==============================] - 3s 754us/step - loss: 1.4295 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1019 - val_loss: 1.4517 - val_mean_squared_error: 0.0179 - val_mean_absolute_error: 0.1083\n",
      "Epoch 86/100\n",
      "4104/4104 [==============================] - 3s 793us/step - loss: 1.4474 - mean_squared_error: 0.0177 - mean_absolute_error: 0.1034 - val_loss: 1.4427 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.1017\n",
      "Epoch 87/100\n",
      "4104/4104 [==============================] - 3s 792us/step - loss: 1.4324 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1023 - val_loss: 1.4367 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.1037\n",
      "Epoch 88/100\n",
      "4104/4104 [==============================] - 3s 788us/step - loss: 1.4284 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1026 - val_loss: 1.4267 - val_mean_squared_error: 0.0182 - val_mean_absolute_error: 0.1045\n",
      "Epoch 89/100\n",
      "4104/4104 [==============================] - 3s 775us/step - loss: 1.4229 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1027 - val_loss: 1.4255 - val_mean_squared_error: 0.0159 - val_mean_absolute_error: 0.1000\n",
      "Epoch 90/100\n",
      "4104/4104 [==============================] - 3s 789us/step - loss: 1.4222 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1023 - val_loss: 1.4191 - val_mean_squared_error: 0.0166 - val_mean_absolute_error: 0.1006\n",
      "Epoch 91/100\n",
      "4104/4104 [==============================] - 3s 780us/step - loss: 1.4168 - mean_squared_error: 0.0168 - mean_absolute_error: 0.1020 - val_loss: 1.4204 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.1034\n",
      "Epoch 92/100\n",
      "4104/4104 [==============================] - 3s 815us/step - loss: 1.4213 - mean_squared_error: 0.0174 - mean_absolute_error: 0.1036 - val_loss: 1.4187 - val_mean_squared_error: 0.0157 - val_mean_absolute_error: 0.0985\n",
      "Epoch 93/100\n",
      "4104/4104 [==============================] - 3s 787us/step - loss: 1.4173 - mean_squared_error: 0.0167 - mean_absolute_error: 0.1015 - val_loss: 1.4218 - val_mean_squared_error: 0.0160 - val_mean_absolute_error: 0.0997\n",
      "Epoch 94/100\n",
      "4104/4104 [==============================] - 3s 745us/step - loss: 1.4223 - mean_squared_error: 0.0171 - mean_absolute_error: 0.1026 - val_loss: 1.4231 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.1002\n",
      "Epoch 95/100\n",
      "4104/4104 [==============================] - 3s 752us/step - loss: 1.4200 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1025 - val_loss: 1.4207 - val_mean_squared_error: 0.0154 - val_mean_absolute_error: 0.0980\n",
      "Epoch 96/100\n",
      "4104/4104 [==============================] - 3s 751us/step - loss: 1.4174 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1029 - val_loss: 1.4196 - val_mean_squared_error: 0.0161 - val_mean_absolute_error: 0.1008\n",
      "Epoch 97/100\n",
      "4104/4104 [==============================] - 3s 776us/step - loss: 1.4143 - mean_squared_error: 0.0169 - mean_absolute_error: 0.1025 - val_loss: 1.4206 - val_mean_squared_error: 0.0171 - val_mean_absolute_error: 0.1026\n",
      "Epoch 98/100\n",
      "4104/4104 [==============================] - 3s 750us/step - loss: 1.4152 - mean_squared_error: 0.0172 - mean_absolute_error: 0.1029 - val_loss: 1.4033 - val_mean_squared_error: 0.0156 - val_mean_absolute_error: 0.0980\n",
      "Epoch 99/100\n",
      "4104/4104 [==============================] - 3s 787us/step - loss: 1.4063 - mean_squared_error: 0.0170 - mean_absolute_error: 0.1027 - val_loss: 1.4177 - val_mean_squared_error: 0.0168 - val_mean_absolute_error: 0.1031\n",
      "Epoch 100/100\n",
      "4104/4104 [==============================] - 3s 786us/step - loss: 1.4176 - mean_squared_error: 0.0176 - mean_absolute_error: 0.1038 - val_loss: 1.4185 - val_mean_squared_error: 0.0155 - val_mean_absolute_error: 0.0987\n",
      "dict_keys(['val_loss', 'val_mean_squared_error', 'val_mean_absolute_error', 'loss', 'mean_squared_error', 'mean_absolute_error'])\n",
      "Test loss: [1.4185192777864184, 0.015478995154824173, 0.09871129770027964]\n",
      "Train loss: [1.419201816964103, 0.016161532021448974, 0.10024176321589691]\n",
      "Mean Squared Error of test:  0.015478994\n",
      "Mean Squared Error of train:  0.016161531\n",
      "Mean Absolute Error of test:  0.09871129\n",
      "Mean Absolute Error of train:  0.10024176\n",
      "Coefficient of Determination for test:  0.18545272287916637\n",
      "Coefficient of Determination for train:  0.2012194189233485\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MLP\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from tensorflow import keras\n",
    "\n",
    "with open('datamrosbmd1103_B1THD', 'rb') as file_handler:\n",
    "    data = pickle.load(file_handler)\n",
    "    X, Y = data.get('X', []).values, data.get('Y', []).values\n",
    "\n",
    "\n",
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(1125, input_dim=1125, kernel_initializer='normal', activation='relu', kernel_regularizer=keras.regularizers.l1(0.01)))\n",
    "    model.add(Dense(500, input_dim=500, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mse', 'mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def main(plot=True):\n",
    "    # fix random seed for reproducibility\n",
    "    # seed = 7\n",
    "\n",
    "    # The below is necessary for starting Numpy generated random numbers in a well-defined initial state.\n",
    "    # numpy.random.seed(seed)\n",
    "    # The below is necessary for starting core Python generated random numbers in a well-defined state.\n",
    "    # rn.seed(seed)\n",
    "\n",
    "    # according to keras documentation, numpy seed should be set before importing keras information regarding setup for obtaining reproducible results using Keras during development in the following link https://keras.io/getting-started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development\n",
    "\n",
    "    # The below tf.set_random_seed() will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
    "    # tf.set_random_seed(seed)\n",
    "\n",
    "    batch_size = 50\n",
    "    # num_classes = 1\n",
    "    # epochs = 50\n",
    "    number_of_data = X.shape[0]\n",
    "    number_of_train_data = int(.8 * number_of_data)\n",
    "    # number_of_test_data = number_of_data - number_of_train_data\n",
    "\n",
    "    # load dataset\n",
    "    x_train, x_test = X[:number_of_train_data, :], X[number_of_train_data:, :]\n",
    "#     mean_train_data = numpy.mean(train_data, axis=0)\n",
    "#     std_train_data = numpy.std(train_data, axis=0)\n",
    "#     x_train = (train_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "#     x_test = (test_data - mean_train_data) / std_train_data  # mean variance normalization\n",
    "    y_train, y_test = Y[:number_of_train_data], Y[number_of_train_data:]\n",
    "\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "\n",
    "    y_train = y_train.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "\n",
    "    model = mlp()\n",
    "    # history = model.fit(x_train, y_train, batch_size=batch_size, epochs=3, verbose=1, validation_data=(x_test, y_test))\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, verbose=1, epochs=100, validation_data=(x_test, y_test))\n",
    "    print(history.history.keys())\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score)\n",
    "\n",
    "    score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    print('Train loss:', score)\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    print('Mean Squared Error of test: ', mean_squared_error(y_test, y_pred))\n",
    "    print('Mean Squared Error of train: ', mean_squared_error(y_train, model.predict(x_train)))\n",
    "\n",
    "    print('Mean Absolute Error of test: ', mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Absolute Error of train: ', mean_absolute_error(y_train, model.predict(x_train)))\n",
    "\n",
    "    print('Coefficient of Determination for test: ', r2_score(y_test, y_pred))\n",
    "    print('Coefficient of Determination for train: ', r2_score(y_train, model.predict(x_train)))\n",
    "\n",
    "    if not plot:\n",
    "        return history.history['loss'], history.history['val_loss']\n",
    "    pyplot.plot(history.history['loss'], 'b-')\n",
    "    pyplot.plot(history.history['val_loss'], 'r-')\n",
    "    pyplot.title('Mean Squared Error Loss: MLP for Total Hip BMD')\n",
    "    pyplot.ylabel('loss')\n",
    "    pyplot.xlabel('epoch')\n",
    "    pyplot.legend(['Train Data', 'Test Data'], loc='upper right')\n",
    "    pyplot.savefig('mlp_B1THD_MSE')\n",
    "    pyplot.show()\n",
    "    \n",
    "    # Plot the predicted value against the actual value\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.scatter(y_test, y_pred)\n",
    "    ax.plot([y_test.min(), y_test.max()], [y_pred.min(), y_pred.max()], 'k--', lw=4)\n",
    "    pyplot.title('Scatter plot of Measured vs. Predicted : MLP for Total Hip BMD')\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    pyplot.savefig('mlp_B1THD_scatter')\n",
    "    pyplot.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of regression ML model by using 5 * 2 cv paired t test for linear vs. random forest\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=linear,\n",
    "                          estimator2=rf,\n",
    "                          X=X, y=Y,\n",
    "                          random_seed=1)\n",
    "\n",
    "print(\"t statistic: %.5f\" % t)\n",
    "print(\"p avlue: %.5f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of regression ML model by using 5 * 2 cv paired t test for linear vs. gb\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=linear,\n",
    "                          estimator2=gb,\n",
    "                          X=X, y=Y,\n",
    "                          random_seed=2)\n",
    "\n",
    "print(\"t statistic: %.5f\" % t)\n",
    "print(\"p avlue: %.5f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of regression ML model by using 5 * 2 cv paired t test for rf vs. gb\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=rf,\n",
    "                          estimator2=gb,\n",
    "                          X=X, y=Y,\n",
    "                          random_seed=1)\n",
    "\n",
    "print(\"t statistic: %.5f\" % t)\n",
    "print(\"p avlue: %.5f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of regression ML model by using 5 * 2 cv paired t test for linear vs. mlp\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras import optimizers\n",
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(20, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(1, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "mlp = mlp()\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=linear,\n",
    "                          estimator2=mlp,\n",
    "                          X=X, y=Y,\n",
    "                          random_seed=2)\n",
    "\n",
    "print(\"t statistic: %.5f\" % t)\n",
    "print(\"p avlue: %.5f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of regression ML model by using 5 * 2 cv paired t test for rf vs. mlp\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras import optimizers\n",
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(20, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(1, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "mlp = mlp()\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=rf,\n",
    "                          estimator2=mlp,\n",
    "                          X=X, y=Y,\n",
    "                          random_seed=2)\n",
    "\n",
    "print(\"t statistic: %.5f\" % t)\n",
    "print(\"p avlue: %.5f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing of regression ML model by using 5 * 2 cv paired t test for gb vs. mlp\n",
    "\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from mlxtend.evaluate import paired_ttest_5x2cv\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from keras import optimizers\n",
    "def mlp():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(20, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.add(Dense(1, input_dim=21, kernel_initializer='normal', activation='sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "mlp = mlp()\n",
    "linear = LinearRegression()\n",
    "rf = RandomForestRegressor()\n",
    "gb = GradientBoostingRegressor()\n",
    "\n",
    "\n",
    "t, p = paired_ttest_5x2cv(estimator1=gb,\n",
    "                          estimator2=mlp,\n",
    "                          X=X, y=Y,\n",
    "                          random_seed=2)\n",
    "\n",
    "print(\"t statistic: %.5f\" % t)\n",
    "print(\"p avlue: %.5f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
